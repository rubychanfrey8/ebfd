{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "GmGKzVIEvxrh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.reset_option('display.max_colwidth', 100)\n",
        "pd.set_option('display.max_rows', None) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "gWnUYR-Yv0cc",
        "outputId": "e988fc0c-9d81-4ac7-b063-339fd26b409b"
      },
      "outputs": [],
      "source": [
        "ogair_df = pd.read_csv('C:/Users/rubyc/Documents/work/ebfd/requests_and_consultations_airtable_92724.csv')\n",
        "ogair_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jmPvgRDapPU"
      },
      "source": [
        "# 1. Data Cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcGNUEs8YPn4"
      },
      "source": [
        "##1.1 Null Values\n",
        "**Purpose:** Check for the proportion of null values in the data and\n",
        "<br>**Code Breakdown by line:**\n",
        "<br>1. Uses Pandas built-in isnull function to check for null values and calculate the number against the total number of values in the dataframe\n",
        "<br> 2. Makes a dataframe of these proportions we just calculated\n",
        "<br> 3. Sorts them by the highest to lowest proportion\n",
        "<br> 4. Calls the dataframe we just made\n",
        "<br> 5. Replaces all null values (which python reads as NaN) with the string \"None\"\n",
        "<br>**Notes:** None this is very simple and obligatory. We chose to replace NaN with the string \"None\" bc most of what we're doing here is natural language processing, which utelizes functions that are designed to have a strings input and tend to output errors when they're input NaN instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        },
        "id": "qCKqjz5FxgVk",
        "outputId": "6fabbf69-89c4-4a37-f1cf-e88bf68c01ca"
      },
      "outputs": [],
      "source": [
        "null_percentage = ogair_df.isnull().sum() / len(ogair_df)\n",
        "missing_value_df = pd.DataFrame({'proportion_null': null_percentage})\n",
        "missing_value_df = missing_value_df.sort_values('proportion_null', ascending = False)\n",
        "missing_value_df.head(30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqq7kgAyVDoK",
        "outputId": "fd47b250-5589-4dc8-956e-d967e93a7eb1"
      },
      "outputs": [],
      "source": [
        "nullfree_df = ogair_df.dropna(subset='Date Called').fillna('None') #.dropna(subset=['Date Called','QLSP?'])\n",
        "nullfree_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "P-WURjY-3CzM",
        "outputId": "1f534f5d-cc6a-4ea2-8b57-9ee38fb411b3"
      },
      "outputs": [],
      "source": [
        "\n",
        "test_df = nullfree_df.head(5)\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iUN-IrsSa3en"
      },
      "source": [
        "# 2. Parsing out the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBRyVAHpaWlz"
      },
      "source": [
        "##2.1 Callback Dates/Date Processing\n",
        "**Purpose:** Extract the date that the call was returned from the \"Notes\" section and convert the extracted callback date and native call recieved date\n",
        "<br>**Input:** The name of a dataframe, the column that the noted dates are in, and the column that the full call cates are in\n",
        "<br>**Output:** A list of the callback dates in datetime format\n",
        "<br>**Code Breakdown:**\n",
        "1.  Creates empty list to later fill\n",
        "2. Two regular expressions are defined as \"yearpattern\" and \"datepattern\" - yearpattern identifies four numerical digits in a row and datepattern identifies numbers 1-12 immediately followed by a slash immediately followed by numbers 1-31. I have no idea how regular expression syntax works those were generated w Chatgpt\n",
        "3. Opens a for loop that'll go through every row in the column that you've defined as containing the callback dates, defining the contents of each row as \"note\"\n",
        "  1. Within the for loop, we search the contents of the\n",
        "5. Replaces all null values (which python reads as NaN) with the string \"None\"\n",
        "**Notes:** None this is very simple and obligatory. We chose to replace NaN with the string \"None\" bc most of what we're doing here is natural language processing, which utelizes functions that are designed to have a strings input and tend to output errors when they're input NaN instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "2c3j4vYTx9J8"
      },
      "outputs": [],
      "source": [
        "def pull_callback_date(df, datecol, yearcol):\n",
        "  #designed for input: nullfree_df, Notes, Date Called\n",
        "  callback_date_l = []\n",
        "  yearpattern = r'\\d{4}'\n",
        "  datepattern = r'\\b(0?[1-9]|1[0-2])/(0?[1-9]|[12][0-9]|3[01])\\b'\n",
        "  for note in df[datecol]: #can i do for note, date in df[datecol], df[yearcol]??? \n",
        "    #  try:\n",
        "    datefind = re.search(datepattern, note)\n",
        "    if datefind:\n",
        "      callbackdate = datefind.group()\n",
        "      date = df[df[datecol]==note][yearcol].iloc[0] ##identifies the whole row of where note is a given note, so won't work if it's not unique \n",
        "      yearfind = re.search(yearpattern, date)\n",
        "      if yearfind:\n",
        "      #for date in df[yearcol]: #this for loop should not be nested here like this \n",
        "        wholedate = (callbackdate + \"/\" + yearfind.group())\n",
        "        final_datetime = pd.to_datetime(wholedate)\n",
        "      #print(yearfind)\n",
        "        callback_date_l.append(final_datetime)\n",
        "      else: callback_date_l.append(None)\n",
        "    else: callback_date_l.append(None)\n",
        "      #except Exception as e:\n",
        "      #    print(f\"I'm a dumb robot and couldn't FUCKING process {note}, because {e}\")\n",
        "  return callback_date_l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in nullfree_df: \n",
        "    print(i)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "yearpattern = r'\\d{4}'\n",
        "yearfind = re.search(yearpattern, nullfree_df['Date Called'][1])\n",
        "yearfind.group()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nullfree_df['callback date datetime'] = pull_callback_date(nullfree_df, 'Notes', 'Date Called')\n",
        "nullfree_df['call date datetime'] = pd.to_datetime(nullfree_df['Date Called'])\n",
        "nullfree_df.info()\n",
        "#nullfree_df['callback date datetime'] = pd.to_datetime(nullfree_df['callback date datetime'], errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "#referral_org_s = nullfree_df.groupby('Referral From (Agency/Individual)').size()\n",
        "#referral_org_s.to_frame().rename({0: \"Count\"}, axis = 1).reset_index().sort_values(\"Count\", ascending = False)\n",
        "#len(nullfree_df['Referral From (Agency/Individual)'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nullfree_df['call date datetime'][34]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_date_differences(df):\n",
        "    # Create a new column to store the date differences\n",
        "    df['date_difference'] = None\n",
        "    \n",
        "    # Iterate through the rows of the DataFrame\n",
        "    for index, row in df.iterrows():\n",
        "        call_date = row['call date datetime']\n",
        "        callback_date = row['callback date datetime']\n",
        "        #try:\n",
        "        if callback_date is None:\n",
        "            continue\n",
        "        #date_difference = (callback_date - call_date).days  # or use .total_seconds() for a more precise measure\n",
        "        #df.at[index, 'date_difference'] = date_difference #stores it in a new column idk how this line works \n",
        "        print(call_date, callback_date)\n",
        "        #except Exception as e:\n",
        "            #print(f\"I'm a dumb robot and couldn't FUCKING process {row}, because {e}\")    \n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "calculate_date_differences(nullfree_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n",
        "░░░░░░░░░░░░░░░░█████████████░░░░░░░░░░░\n",
        "░░░░░░░░░████████░░░░░░░░░░░█████░░░░░░░\n",
        "░░░░░░███░░░░░░░░██████░░░░░░░░░██░░░░░░\n",
        "░░░░░░█░░░░░░░░░░█░░░░█░░░░░░░░░░█░░░░░░\n",
        "░░░░░██░░░░░░░░░░░░░░░░░░░░░░░░███░░░░░░\n",
        "░░░░░░█░░░░░░░░░░░░░░░░░░░░░█████░░░░░░░\n",
        "░░░░░█████░░░░░░░░░░░░░░██████░░█░░░░░░░\n",
        "░░░░░░█░░███████████████░█░░░█░░█░░░░░░░\n",
        "░░░░░░░█░░░░░█░░░░░█░░░░░█░░░█░░█░░░░░░░\n",
        "░░░░░░░██░░░░█░░░░░█░░░░░█░░░█░█░░░░░░░░\n",
        "░░░░░░░░█░░░░██░░░░█░░░░█░░░░█░█░░░░░░░░\n",
        "░░░░░░░░░█░░░░█░░░░█░░░░█░░░█░██░░░░░░░░\n",
        "░░░░░░░░░█░░░░░█░░░█░░░░█░░░█░█░░░░░░░░░\n",
        "░░░░░░░░░██░░░░██░░█░░░██░░░█░█░░░░░░░░░\n",
        "░░░░░░░░░░█░░░░░█░░██░░█░░░░█░█░░░░░░░░░\n",
        "░░░░░░░░░░████░░█░░░█░░█░░░█░░█░░░░░░░░░\n",
        "░░░░░░░░░░░░░██████████████████░░░░░░░░░\n",
        "░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░░\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76Js4LGlP5Av",
        "outputId": "d1f8ee3b-3a94-4b47-c255-29e7f1855acb"
      },
      "outputs": [],
      "source": [
        "pd.to_datetime(nullfree_df['Date Called'][2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calldate_datetime(df, col):\n",
        "  calldate_l = []\n",
        "  for date in df[col]:\n",
        "    calldatetime = pd.to_datetime(date)\n",
        "    calldate_l.append(calldatetime)\n",
        "  return calldate_l\n",
        "## I don't think calldate_l ever gets put into the df\n",
        "\n",
        "nullfree_df['callback date datetime'] = pull_callback_date(nullfree_df, 'Notes', 'Date Called')\n",
        "nullfree_df['call date datetime'] = calldate_datetime(nullfree_df, 'Date Called')\n",
        "#nullfree_df['callback time'] = nullfree_df['call date datetime'] - nullfree_df['callback date datetime']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "referrals_s = nullfree_df.groupby('Referral From (Agency/Individual)').size()\n",
        "referrals_df = referrals_s.to_frame().rename({0: \"Count\"}, axis = 1).reset_index()\n",
        "referrals_df.sort_values(\"Count\", ascending = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "4AY5WhI0QOLT",
        "outputId": "a735969d-3dbc-4b3d-b239-96322bed5e9c"
      },
      "outputs": [],
      "source": [
        "if date != 'None':\n",
        "    calldate_l.append(pd.to_datetime(date))\n",
        "else:\n",
        "    calldate_l.append('None')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "awUHqPXaIvzM"
      },
      "outputs": [],
      "source": [
        "nullfree_df['callback_date'] = pull_callback_date(nullfree_df, 'Notes', 'Date Called')\n",
        "nullfree_df['Date Called Formatted'] = calldate_datetime(nullfree_df, 'Date Called')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "MEpqKnuxLAXN",
        "outputId": "1d3ba5fc-f45b-4e13-d377-07f906b589c2"
      },
      "outputs": [],
      "source": [
        "nullfree_df.to_csv('airtablewdates2.csv', index=True)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0sMD4wb2nlb",
        "outputId": "03280d37-684b-4e24-b50d-48cca2b7775c"
      },
      "outputs": [],
      "source": [
        "callback_date_l = []\n",
        "yearpattern = r'\\d{4}'\n",
        "datepattern_old = r'\\d{1,2}/\\d{1,2}'\n",
        "datepattern = r'\\b(0?[1-9]|1[0-2])/(0?[1-9]|[12][0-9]|3[01])\\b'\n",
        "for note in nullfree_df['Notes']:\n",
        "  #  try:\n",
        "    #need to if/then for if it's empty empty\n",
        "  datefind = re.search(datepattern, note)\n",
        "  if datefind:\n",
        "    callbackdate = datefind.group()\n",
        "    for date in nullfree_df['Date Called']:\n",
        "      yearfind = re.search(yearpattern, date)\n",
        "    wholedate = (callbackdate + \"/\" + yearfind.group())\n",
        "    final_datetime = pd.to_datetime(wholedate)\n",
        "    callback_date_l.append(final_datetime)\n",
        "    #except Exception as e:\n",
        "    #    print(f\"I'm a dumb robot and couldn't FUCKING process {note}, because {e}\")\n",
        "callback_date_l\n",
        "#print(datefind)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yp_cgUSZ0CTo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
